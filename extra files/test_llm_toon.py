# File: test_llm_toon.py

import json
import os
from cerebras.cloud.sdk import Cerebras
from toon_format import decode
from dotenv import load_dotenv

# --- Setup ---
load_dotenv()
client = Cerebras(api_key=os.getenv("CEREBRAS_API_KEY"))
MODEL = "llama-3.3-70b"

# ==============================================================================
# PROMPT FOR JSON -> TOON CONVERSION
# This prompt is given to the LLM.
# ==============================================================================
toon_generation_prompt_base = '''You are an expert data serializer. Convert the following JSON object to TOON format.

RULES:
- Output ONLY the TOON format. Do not add any extra text, markdown, or explanations.
- Simple field: `key: value`
- String values with spaces or special chars: quote them (e.g., `message: "Hello, world!"`)
- Object: `key:` then indented fields on new lines
- Array of primitives: `tags[N]: a,b,c`
- Array of FLAT objects (only scalars): `users[N]{id,name}:` then comma-separated rows
- Array of COMPLEX objects (with nesting or lists): `users[N]:` then use `- field: value` blocks for each item
- Null value: `null`
- NEVER invent, omit, or reorder fields.

Now, convert this JSON to TOON. Output ONLY TOON.
JSON:
'''

def run_json_to_toon_test(original_data_obj, test_name="Test"):
    """
    Tests the LLM's ability to convert a given JSON object to TOON format.
    """
    print(f"\n{'='*90}")
    print(f"ğŸ§ª RUNNING: {test_name} (JSON -> TOON Conversion)")
    print('='*90)

    # --- Start with the ground-truth JSON ---
    # Convert the Python object to a compact JSON string
    json_A = json.dumps(original_data_obj, separators=(',', ':'), ensure_ascii=False)
    
    print("\n" + "="*90)
    print("ğŸ“„ JSON_A (Input to LLM):")
    # Pretty print for readability
    print(json.dumps(original_data_obj, indent=2))

    # --- LLM Call: Generate TOON from JSON_A ---
    toon_prompt = toon_generation_prompt_base + json.dumps(original_data_obj, indent=2) # Pretty print for LLM
    resp_toon = client.chat.completions.create(
        messages=[{"role": "user", "content": toon_prompt}],
        model=MODEL,
        stream=False,
        max_completion_tokens=2048,
        temperature=0.1
    )
    toon_out = resp_toon.choices[0].message.content.strip()

    # --- LOCAL: Decode the LLM's TOON back to JSON_B ---
    try:
        decoded_obj = decode(toon_out)
    except Exception as e:
        print(f"âŒ LOCAL DECODE FAILED: {e}")
        decoded_obj = None

    # === DISPLAY RESULTS ===
    print("\n" + "="*90)
    print("ğŸ“„ TOON (Generated by LLM):")
    print(toon_out)
    
    # --- Memory Comparison ---
    json_bytes = len(json_A.encode('utf-8'))
    toon_bytes = len(toon_out.encode('utf-8'))
    print("\n" + "="*90)
    print("ğŸ“Š MEMORY COMPARISON (UTF-8 Bytes):")
    print(f"JSON size  : {json_bytes:,} bytes")
    print(f"TOON size  : {toon_bytes:,} bytes")
    if json_bytes > 0:
        reduction = (1 - toon_bytes / json_bytes) * 100
        saved = json_bytes - toon_bytes
        print(f"Reduction  : {reduction:.1f}%")
        print(f"Saved      : {saved:,} bytes")

    # --- Programmatic Validation ---
    print("\n" + "="*90)
    print("âœ… VALIDATION (Local Python):")
    if original_data_obj == decoded_obj:
        print("Result: âœ… PASS - Decoded object matches the original.")
        return True
    else:
        print("Result: âŒ FAIL - Decoded object does NOT match the original.")
        print("\nOriginal Object:")
        print(json.dumps(original_data_obj, indent=2))
        print("\nDecoded Object:")
        print(json.dumps(decoded_obj, indent=2))
        return False
    print("="*90)


# ============================================================================
# TEST CASES (as Python Dictionaries)
# ============================================================================
test_data = {
    "Fitness App": {
        "app": "FitTrack",
        "users": [
            {"id": 201, "name": "Maya", "age": None, "plan": "premium", "goals": ["weight_loss", "strength"]},
            {"id": 202, "name": "Ravi", "age": 35, "plan": "basic", "goals": ["running"]}
        ]
    },
    "E-Commerce Order": {
        "order_id": "ORD-789",
        "customer": {"id": 501, "name": "Priya Mehta", "email": "priya@example.com"},
        "items": [
            {"sku": "LAP-202", "name": "Gaming Laptop", "price": 1200, "metadata": {"warranty": "2 years", "category": "Electronics"}},
            {"sku": "MOUSE-55", "name": "Wireless Mouse", "price": 25, "metadata": {"warranty": "1 year", "category": "Accessories"}}
        ],
        "status": "shipped"
    },
    "Analytics Data": {
        "metrics": [
            {"date": "2025-01-01", "views": 6890, "clicks": 401, "conversions": 23, "revenue": 6015.59, "bounceRate": 0.63},
            {"date": "2025-01-02", "views": 6940, "clicks": 323, "conversions": 37, "revenue": 9086.44, "bounceRate": 0.36}
        ]
    },
    "CI/CD Pipeline": {
        "pipeline_name": "WebApp-Deploy", "trigger_on": ["push:main", "pull_request:main"], "env": {},
        "stages": [
            {"name": "Build", "jobs": [{"name": "Compile-App", "runner": "ubuntu-latest", "steps": [{"name": "Checkout", "uses": "actions/checkout@v2"}, {"name": "Build", "run": "npm run build"}]}]},
            {"name": "Test", "jobs": [{"name": "Unit-Tests", "runner": "ubuntu-latest", "steps": [{"name": "Run tests", "run": "npm test"}]}, {"name": "Linting", "runner": "ubuntu-latest", "steps": [{"name": "Run linter", "run": "npm run lint"}]}]}
        ]
    }
}

# ============================================================================
# RUN
# ============================================================================
print("ğŸš€ STARTING JSON -> TOON CONVERSION & VALIDATION PIPELINE")
results = {}
for name, data_obj in test_data.items():
    results[name] = run_json_to_toon_test(data_obj, name)

print("\n\n" + "="*40)
print("ğŸ¯ FINAL SUMMARY")
print("="*40)
for name, passed in results.items():
    status = 'âœ… PASS' if passed else 'âŒ FAIL'
    print(f"{name:<20} â†’ {status}")
print("="*40)